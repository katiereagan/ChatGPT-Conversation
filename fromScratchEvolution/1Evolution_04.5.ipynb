{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e8f801e",
   "metadata": {},
   "source": [
    "### My notes:\n",
    "\n",
    "As I continued to work with ChatGPT and see it convey its knowledge,\n",
    "I was curious about where it came from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca125005",
   "metadata": {},
   "source": [
    "### User:\n",
    "\n",
    "Where is your, ChatGPT, knowledge stored?\n",
    "\n",
    "### Chat GPT:\n",
    "\n",
    "As an AI language model, my knowledge is not stored in a single physical location. \n",
    "I am powered by the GPT-3.5 architecture developed by OpenAI. \n",
    "My knowledge is derived from a vast amount of text data collected from diverse sources available on the internet \n",
    "up until my September 2021 knowledge cutoff. \n",
    "This knowledge includes information on a wide range of topics, including but not limited to \n",
    "science, history, technology, and more.\n",
    "\n",
    "During my training, the model was exposed to patterns and relationships in the text data to learn \n",
    "how to generate human-like responses based on the input provided to me. \n",
    "However, it's important to note that while I strive to provide accurate and up-to-date \n",
    "information, there may still be limitations and potential inaccuracies in my responses. \n",
    "Therefore, it's always a good idea to verify information from reliable sources and \n",
    "consult domain experts for critical or specialized topics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f1de8c",
   "metadata": {},
   "source": [
    "### User:\n",
    "\n",
    "How does your system access the internet?\n",
    "\n",
    "### Chat GPT:\n",
    "\n",
    "As an AI language model, I don't have direct access to the internet. \n",
    "My responses are generated based on the training data I have been trained on, which includes a vast \n",
    "amount of text data from various sources available on the internet up until my September 2021 knowledge cutoff. \n",
    "This training data helps me provide information and answer questions based on patterns and relationships learned from the text.\n",
    "\n",
    "It's important to note that while I can provide information based on the training data, \n",
    "I cannot browse the internet, access real-time information, or retrieve information from websites or external sources. \n",
    "My responses are limited to the knowledge and information I acquired during my training, \n",
    "and I cannot provide information on events or developments that occurred after my knowledge cutoff in September 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e9f87e",
   "metadata": {},
   "source": [
    "### User:\n",
    "\n",
    "How was your training data inputed into your system?\n",
    "\n",
    "### Chat GPT:\n",
    "\n",
    "The training data for AI language models like ChatGPT is typically collected from various sources on the internet. The specific process for inputting the training data can be summarized as follows:\n",
    "\n",
    "1. Data Collection: Large amounts of text data are collected from diverse sources such as books, articles, websites, and other publicly available written material. The data collection process aims to capture a wide range of topics, styles, and domains to make the model as versatile as possible.\n",
    "\n",
    "2. Preprocessing: The collected text data goes through preprocessing steps to clean and normalize the data. This may involve removing irrelevant or duplicate content, formatting the text, and preparing it for further processing.\n",
    "\n",
    "3. Tokenization: The preprocessed text is tokenized, which involves breaking it down into smaller units such as words, subwords, or characters. Tokens are the basic units of input for the language model.\n",
    "\n",
    "4. Training Setup: The tokenized data is then used to train the language model. Training involves feeding the model the input tokens and training it to predict the next token in a sequence. This process helps the model learn the statistical patterns and relationships in the data.\n",
    "\n",
    "5. Iterative Training: The training process is typically performed iteratively using powerful computational resources. The model goes through multiple training epochs, with each epoch consisting of many iterations, to refine its language generation capabilities and improve its performance.\n",
    "\n",
    "6. Fine-tuning and Validation: After the initial training, models may undergo additional fine-tuning on specific datasets or tasks to specialize their behavior or adapt them to specific applications. This process involves using specialized datasets and validation techniques to optimize the model's performance for specific use cases.\n",
    "\n",
    "It's important to note that the specific details of the training pipeline and the exact sources and methods used for training AI language models like ChatGPT may vary depending on the implementation and updates made by OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0510757",
   "metadata": {},
   "source": [
    "### User:\n",
    "\n",
    "Is your knowledge limited to publicly available sources?\n",
    "\n",
    "### Chat GPT:\n",
    "\n",
    "Yes, my knowledge is primarily based on publicly available sources. \n",
    "During the training process, the AI model is trained on a vast amount of text data collected from diverse sources that are publicly accessible on the internet. \n",
    "This includes sources such as books, articles, websites, and other written material.\n",
    "\n",
    "However, it's important to note that while the training data consists of publicly available information, the specific sources and documents used for training are not disclosed. \n",
    "Additionally, the training data is a representation of the text that was available up until my September 2021 knowledge cutoff, and I do not have access to real-time or proprietary information.\n",
    "\n",
    "It's always a good idea to verify information from reliable and up-to-date sources, especially when it comes to time-sensitive or critical information. \n",
    "While I strive to provide accurate and helpful responses, there may still be limitations and potential inaccuracies in my knowledge, so exercising caution and consulting multiple sources is advisable when necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785890ef",
   "metadata": {},
   "source": [
    "### User:\n",
    "\n",
    "Do you have a way of citing from where you gathered your information,\n",
    "or does your system use a collection of data to form logical statements?\n",
    "\n",
    "### Chat GPT:\n",
    "\n",
    "As an AI language model, I don't have direct access to information about specific sources or the ability to provide citations in the traditional sense. \n",
    "I don't have access to the internet or a database of specific sources to retrieve information from.\n",
    "\n",
    "The responses I generate are based on patterns, relationships, and knowledge learned from the large corpus of text data I was trained on. \n",
    "My training includes a mixture of licensed data, data created by human trainers, and publicly available data. \n",
    "This diverse training dataset enables me to generate responses and provide information on a wide range of topics.\n",
    "\n",
    "It's important to note that while I strive to provide accurate and up-to-date information, my responses should be considered as generated content and not as a direct citation from specific sources. \n",
    "I do not have the ability to independently verify the accuracy of the information or provide a list of sources for a particular response.\n",
    "\n",
    "If you need specific information or want to cite sources, it's recommended to consult reliable and authoritative sources directly, perform research from trusted references, and follow appropriate citation practices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918d4e64",
   "metadata": {},
   "source": [
    "### My notes:\n",
    "\n",
    "Bucket-list item: interview a computer *done!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
